# -*- coding: utf-8 -*-
"""image_to_amime_with_mxnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LTzdjBxSsx9vAmfF8Xt81FHVgSwGSUYU
"""

from PIL import Image
import torch
import IPython
from IPython.display import display
import numpy as np


input_image = "DSC00438.JPG"#@param {type:"string"}
anime = "face_paint_512_v2" #@param ["face_paint_512_v2", "celeba_distill", "face_paint_512_v1", "paprika"] {allow-input: false}

anime = torch.hub.load("bryandlee/animegan2-pytorch:main", "generator", pretrained=anime)
anime = anime.cuda()
face2paint = torch.hub.load("bryandlee/animegan2-pytorch:main", "face2paint", size=512)

def image_to_paint(img):
    #type np
    img = Image.fromarray(np.uint8(img))
    out = face2paint(anime, img, device='cuda')
    out = np.array(out.resize((112,112)))
    return out

# Import modules
import sys, dlib
sys.path.append('eameo-faceswap-generator')

import numpy as np
import faceBlendCommon as fbc
# import matplotlib.pyplot as plt
from PIL import Image

# get landmark
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("eameo-faceswap-generator/shape_predictor_68_face_landmarks.dat")
get_points = lambda x: np.array(fbc.getLandmarks(detector, predictor, x))

FACIAL_LANDMARKS_IDXS = {
	"mouth": (48, 68),
	# "right_eyebrow": (17, 22),
	# "left_eyebrow": (22, 27),
	# "right_eye": (36, 42),
	# "left_eye": (42, 48),
	"nose": (27, 35),
	# "jaw": (0, 17),
	"eye" : (36, 48),
	"eyebrow" : (17, 27)
 }

def get_crop_boundary(points_subset):
    min_point = np.array([np.min(points_subset[:,0]), np.min(points_subset[:,1])])
    max_point = np.array([np.max(points_subset[:,0]), np.max(points_subset[:,1])])
    return min_point, max_point

def organ_image(image, points, organ = 'mouth'):
    start, end = FACIAL_LANDMARKS_IDXS[organ]
    
    min_point, max_point = get_crop_boundary(points[start:end])
    new_image = np.zeros_like(image)
    new_image[min_point[1]:max_point[1],min_point[0]:max_point[0],:] = image[min_point[1]:max_point[1],min_point[0]:max_point[0],:]

    return new_image

def organ_only_image(image, points):
    new_image = np.zeros_like(image)
    for organ in FACIAL_LANDMARKS_IDXS:

        start, end = FACIAL_LANDMARKS_IDXS[organ]
        
        min_point, max_point = get_crop_boundary(points[start:end])
        
        new_image[min_point[1]:max_point[1],min_point[0]:max_point[0],:] = image[min_point[1]:max_point[1],min_point[0]:max_point[0],:]

    return new_image

def no_organ_image(image, points):
    new_image = np.array(image, copy=True)
    for organ in FACIAL_LANDMARKS_IDXS:

        start, end = FACIAL_LANDMARKS_IDXS[organ]
        
        min_point, max_point = get_crop_boundary(points[start:end])
        
        new_image[min_point[1]:max_point[1],min_point[0]:max_point[0],:] = np.mean(image)

    return new_image

"""#Prepare images"""

# !pip install mxnet >/dev/null

import os
import mxnet as mx

source = 'faces_webface_112x112'
# output = 'faces_webface_112x112_organs'
# output = 'faces_webface_112x112_no_organs'
output = 'faces_webface_112x112_paint'

valid_dataset = 'lfw'

# imgrec = mx.recordio.MXIndexedRecordIO(os.path.join(source, 'train.idx'), os.path.join(source, 'train.rec'), 'r')

# import numpy as np

# s = imgrec.read_idx(0)
# header, _ = mx.recordio.unpack(s)
# if header.flag > 0:
#     header0 = (int(header.label[0]), int(header.label[1]))
#     imgidx = np.array(range(1, int(header.label[0])))
# else:
#     imgidx = np.array(list(imgrec.keys))

from tqdm import tqdm

# record = mx.recordio.MXIndexedRecordIO(os.path.join(output, 'train.idx'), os.path.join(output, 'train.rec'), 'w')
# s = imgrec.read_idx(0)
# record.write_idx(0, s)

# for i in tqdm(imgidx):
#     s = imgrec.read_idx(i)
#     header, img = mx.recordio.unpack(s)
#     sample = mx.image.imdecode(img).asnumpy()
#     try:
#         # sample = organ_image(sample, get_points(sample))
#         sample = image_to_paint(sample)
#         packed_s = mx.recordio.pack_img(header, sample)
#         record.write_idx(i, packed_s)
#     except:
#         pass
# record.close()


import pickle as pkl


with open(os.path.join(source, valid_dataset + '.bin'), 'rb') as f:
    bins, issame_list = pkl.load(f, encoding='bytes')

A = []
B = []
S = []
for s, a, b in tqdm(zip(issame_list, bins[0::2], bins[1::2])):
    try:
        a = mx.image.imdecode(a).asnumpy()
        # pa = get_points(a)
        a = image_to_paint(a)

        b = mx.image.imdecode(b).asnumpy()
        # pb = get_points(b)
        b = image_to_paint(b)

        A.append(a)
        B.append(b)
        S.append(s)
    except:
        pass

bins = []
header = mx.recordio.IRHeader(0, 5, 7, 0)
for i in range(len(A)):
    bins.append(np.flip(A[i], 2))
    bins.append(np.flip(B[i], 2))
for i, x in enumerate(bins):
    packed_i = mx.recordio.pack_img(header, x)
    _, img_only = mx.recordio.unpack(packed_i)
    bins[i] = img_only

with open(os.path.join(output, valid_dataset + '.bin'), 'wb') as f:
    pkl.dump((bins, S), f)